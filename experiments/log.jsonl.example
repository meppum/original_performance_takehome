{"iteration_id":1,"timestamp_utc":"2026-02-01T21:30:00Z","branch":"perf/optimize-kernel (worktree)","base_branch":"main","base_sha":"5452f74","head_sha":"(uncommitted)","files_changed":["perf_takehome.py"],"tests_diff_empty":true,"valid":true,"cycles":1878,"delta_vs_best":435,"strategy_tags":["vliw-pack","simd","reduce-stores","hash-fusion","early-depth-skip-gather"],"hypothesis":"A task-graph + list scheduler plus hash fusion and fewer gathers will reduce cycles below naive packing.","change_summary":["Rewrote build_kernel to emit a scratch-aware task DAG and pack into VLIW bundles","Kept values/indices in scratch (single vload/vstore)","Fused 3 hash stages via valu.multiply_add","Special-cased early-depth rounds (0/1/2 and 11/12/13) to avoid per-lane gathers"],"result_summary":"PASS correctness; cycles=1878 (fails <1790)","merged_to_main":false,"notes":"Reconstructed from earlier work; this state was not committed. Baseline for later scheduling-heuristic improvements."}
{"iteration_id":2,"timestamp_utc":"2026-02-01T22:20:00Z","branch":"perf/optimize-kernel (worktree)","base_branch":"main","base_sha":"5452f74","head_sha":"(uncommitted)","files_changed":["perf_takehome.py"],"tests_diff_empty":true,"valid":false,"cycles":null,"delta_vs_best":null,"strategy_tags":["dep-break","scheduler","anti-dep"],"hypothesis":"Dropping WAR/anti-dependencies will allow tighter packing and fewer bubbles.","change_summary":["Removed WAR/anti-dependency edges from the scheduler dependency graph"],"result_summary":"FAIL correctness (incorrect output values)","merged_to_main":false,"notes":"Dropping anti-deps caused stale scratch reads within a bundle (writes commit end-of-cycle). Needs more careful hazard modeling if revisited."}
{"iteration_id":3,"timestamp_utc":"2026-02-01T22:40:00Z","branch":"perf/optimize-kernel (worktree)","base_branch":"main","base_sha":"5452f74","head_sha":"(uncommitted)","files_changed":["perf_takehome.py"],"tests_diff_empty":true,"valid":true,"cycles":1913,"delta_vs_best":470,"strategy_tags":["branch-elim","cmov-mask","flow-avoid"],"hypothesis":"Replace flow.vselect with mask-based selects to remove flow-engine pressure.","change_summary":["Added mask-select logic for early-depth node choice using valu ops (no flow slots)"],"result_summary":"PASS correctness; cycles=1913 (worse)","merged_to_main":false,"notes":"Even though flow slots went to 0, extra valu ops outweighed the benefit."}
{"iteration_id":4,"timestamp_utc":"2026-02-01T23:40:00Z","branch":"perf/optimize-kernel","base_branch":"main","base_sha":"5452f74","head_sha":"4ba7986","files_changed":["perf_takehome.py"],"tests_diff_empty":true,"valid":true,"cycles":1443,"delta_vs_best":0,"strategy_tags":["scheduler-heuristic","vliw-pack","dep-break"],"hypothesis":"Scheduling short critical-path tasks first will improve overlap and keep load/valu/alu utilization high.","change_summary":["Changed scheduler heuristic to prefer shorter critical-path tasks (cp ascending)"],"result_summary":"PASS correctness; cycles=1443 (passes all thresholds except <1363)","merged_to_main":true,"notes":"Merged to main via PR #1 (squash). Current best; next likely lever is further reducing remaining gather/load work or improving hash+idx overlap."}
